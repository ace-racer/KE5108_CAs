{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boiler plate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support, accuracy_score, cohen_kappa_score\n",
    "%matplotlib inline\n",
    "\n",
    "class_names = [\"A\", \"B\", \"None\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    #     print(\"Normalized confusion matrix\")\n",
    "    # else:\n",
    "    #     print('Confusion matrix, without normalization')\n",
    "\n",
    "    # print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test dataset shape 4000, 10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['age', 'income', 'avbal', 'avtrans', 'sex_F', 'sex_M',\n",
       "       'mstatus_divorced', 'mstatus_married', 'mstatus_single',\n",
       "       'mstatus_widowed', 'occupation_IT', 'occupation_construct',\n",
       "       'occupation_education', 'occupation_finance', 'occupation_government',\n",
       "       'occupation_legal', 'occupation_manuf', 'occupation_medicine',\n",
       "       'occupation_retired', 'education_postgrad', 'education_professional',\n",
       "       'education_secondary', 'education_tertiary', 'children_0', 'children_1',\n",
       "       'children_2', 'children_3', 'children_4'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"original_data/custdatabase.csv\")\n",
    "df_copy = pd.read_csv(\"original_data/custdatabase.csv\")\n",
    "print('Test dataset shape {0}, {1}'.format(df.shape[0], df.shape[1]))\n",
    "\n",
    "# strip the spaces in the header, if present\n",
    "df = df.rename(columns=lambda x: x.strip())\n",
    "df.columns.values\n",
    "\n",
    "categorical_features = [\"sex\", \"mstatus\", \"occupation\", \"education\", \"children\"]\n",
    "df[categorical_features].head()\n",
    "df[\"children\"] = df[\"children\"].astype(str)\n",
    "label_encoders = {}\n",
    "label_mappings = {}\n",
    "for categorical_feature in categorical_features:\n",
    "    label_encoders[categorical_feature] = preprocessing.LabelEncoder()\n",
    "    df[categorical_feature + \"Num\"] = label_encoders[categorical_feature].fit_transform(df[categorical_feature])\n",
    "    label_mappings[categorical_feature] = label_encoders[categorical_feature].classes_\n",
    "\n",
    "label_encoders = {}\n",
    "label_mappings = {}\n",
    "for categorical_feature in categorical_features:\n",
    "    label_encoders[categorical_feature] = preprocessing.LabelEncoder()\n",
    "    df[categorical_feature + \"Num\"] = label_encoders[categorical_feature].fit_transform(df[categorical_feature])\n",
    "    label_mappings[categorical_feature] = label_encoders[categorical_feature].classes_\n",
    "\n",
    "for categorical_feature in categorical_features:\n",
    "    for class_value in label_mappings[categorical_feature]:\n",
    "        df[categorical_feature + \"_\" + (class_value)] = df[categorical_feature] == np.array([(class_value)] * df.shape[0])\n",
    "        df[categorical_feature + \"_\" + (class_value)] = df[categorical_feature + \"_\" + (class_value)].astype(int)\n",
    "\n",
    "# drop the categorical values\n",
    "df = df.drop(categorical_features, axis=1)\n",
    "\n",
    "df.head()\n",
    "\n",
    "# remove num columns for Neural networks\n",
    "shouldRemoveNumColumns = True\n",
    "\n",
    "if shouldRemoveNumColumns:\n",
    "    num_columns = [\"sexNum\", \"mstatusNum\", \"occupationNum\", \"educationNum\", \"childrenNum\"]\n",
    "    df = df.drop(num_columns, axis=1)\n",
    "else:\n",
    "    print(\"Not dropping the num columns\")\n",
    "df.head()\n",
    "\n",
    "train_df = pd.read_csv(\"working_data/trial_promo_training.csv\")\n",
    "features_to_scale = [\"age\", \"income\", \"avbal\", \"avtrans\"]\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "# fit on the train data\n",
    "train_df[features_to_scale] = min_max_scaler.fit(train_df[features_to_scale])\n",
    "\n",
    "# transform the test data\n",
    "df[features_to_scale] = min_max_scaler.transform(df[features_to_scale])\n",
    "df.head()\n",
    "\n",
    "customer_ids = df[\"index\"]\n",
    "df = df.drop(\"index\", axis=1)\n",
    "df.head()\n",
    "\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the different models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "# the model must be in the models folder\n",
    "model_to_use = \"model-004-0.82.h5\"\n",
    "model = load_model('models/'+model_to_use)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
